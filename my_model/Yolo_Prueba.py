import os
import sys
import argparse
import glob
import time
import serial 
import json
import threading
from flask import Response, Flask

import cv2
import numpy as np
from ultralytics import YOLO

# --- NUEVO: Configuraci√≥n del servidor de streaming ---
output_frame = None
lock = threading.Lock()
# Inicializar la aplicaci√≥n Flask
app = Flask(__name__)

# --- INICIO DE LA MODIFICACI√ìN 1: A√±adir funci√≥n de recorte ---
def crop_center(img, crop_width, crop_height):
    """Recorta la imagen desde el centro a las dimensiones deseadas."""
    img_height, img_width, _ = img.shape
    start_x = (img_width - crop_width) // 2
    start_y = (img_height - crop_height) // 2
    
    # Asegurarse de que las coordenadas no sean negativas (si la img es m√°s peque√±a que el recorte)
    if start_x < 0 or start_y < 0:
        print(f"ADVERTENCIA: La imagen original ({img_width}x{img_height}) es m√°s peque√±a que el recorte deseado ({crop_width}x{crop_height}). No se recortar√°.")
        return img

    end_x = start_x + crop_width
    end_y = start_y + crop_height
    
    # Realiza el recorte usando slicing de NumPy
    return img[start_y:end_y, start_x:end_x]
# --- FIN DE LA MODIFICACI√ìN 1 ---

# Define and parse user input arguments
# (El c√≥digo de argparse se mantiene igual)
parser = argparse.ArgumentParser()
parser.add_argument('--model', help='Path to YOLO model file (example: "runs/detect/train/weights/best.pt")',
                    required=True)
parser.add_argument('--source', help='Image source, can be image file ("test.jpg"), \
                    image folder ("test_dir"), video file ("testvid.mp4"), index of USB camera ("usb0"), or index of Picamera ("picamera0")', 
                    required=True)
parser.add_argument('--thresh', help='Minimum confidence threshold for displaying detected objects (example: "0.4")',
                    default=0.6)
parser.add_argument('--resolution', help='Resolution in WxH to display inference results at (example: "640x480"), \
                    otherwise, match source resolution',
                    default=None)
parser.add_argument('--record', help='Record results from video or webcam and save it as "demo1.avi". Must specify --resolution argument to record.',
                    action='store_true')

args = parser.parse_args()


# Parse user inputs
model_path = args.model
img_source = args.source
min_thresh = float(args.thresh) # Asegurarse de que sea float
user_res = args.resolution
record = args.record

# ######################################################
# ## CONFIGURACI√ìN DEL ROBOT Y GRID ##
# ######################################################
# Ajusta estos par√°metros seg√∫n tu configuraci√≥n
SERIAL_PORT = 'COM3'  # <--- CAMBIA ESTO (ej. 'COM3' en Windows, '/dev/ttyACM0' en Linux)
BAUD_RATE = 115200
TARGET_CLASS = 'Rude' # Nombre de la clase de maleza en tu modelo YOLO
SERIAL_TIMEOUT = 10

# Configuraci√≥n del Grid
# --- NUEVO: Configuraci√≥n de dimensiones f√≠sicas y archivo ---
CONFIG_FILE = 'config_grilla.json'
GRID_ROWS_CM = 2  # Altura del grid en cm
GRID_COLS_CM = 10 # Ancho del grid en cm

LOG_FILE = 'log_ataques.json'


def resetear_log():
    """Borra el archivo de log y limpia el diccionario en memoria."""
    global posiciones_atacadas_log
    try:
        if os.path.exists(LOG_FILE):
            os.remove(LOG_FILE)
            print("‚úÖ Archivo de log borrado exitosamente.")
        else:
            print("INFO: El archivo de log no exist√≠a, no hay nada que borrar.")
        
        posiciones_atacadas_log.clear() # Limpia el log en memoria
        print(" memoria del robot reiniciada.")

    except OSError as e:
        print(f"‚ö†Ô∏è ERROR: No se pudo borrar el archivo de log. Detalle: {e}")

# ######################################################
# ## NUEVO: FUNCIONES PARA MANEJAR EL LOG DE ATAQUES ##
# ######################################################

def cargar_log_ataques(archivo_log):
    """Carga las posiciones atacadas desde un archivo JSON."""
    try:
        with open(archivo_log, 'r') as f:
            log = json.load(f)
            # JSON guarda claves como string, las convertimos a int si es necesario
            return {int(k): v for k, v in log.items()}
    except FileNotFoundError:
        print(f"INFO: No se encontr√≥ el archivo '{archivo_log}'. Se crear√° uno nuevo.")
        return {} # Devuelve un diccionario vac√≠o si el archivo no existe
    except json.JSONDecodeError:
        print(f"ADVERTENCIA: El archivo '{archivo_log}' est√° corrupto. Se iniciar√° un nuevo log.")
        return {}


def guardar_log_ataques(archivo_log, datos_log):
    """Guarda el diccionario de posiciones atacadas en un archivo JSON."""
    with open(archivo_log, 'w') as f:
        json.dump(datos_log, f, indent=4)

# ######################################################
# ## NUEVO: L√ìGICA DEL SERVIDOR DE STREAMING DE VIDEO ##
# ######################################################
def generate_frames():
    global output_frame, lock
    # Bucle infinito para generar fotogramas para el stream
    while True:
        with lock:
            # Si no hay un fotograma disponible, no hacer nada
            if output_frame is None:
                continue
            # Codificar el fotograma a formato JPEG
            (flag, encoded_image) = cv2.imencode(".jpg", output_frame)
            if not flag:
                continue
        # Entregar el fotograma en formato de bytes
        yield(b'--frame\r\n' b'Content-Type: image/jpeg\r\n\r\n' + 
              bytearray(encoded_image) + b'\r\n')

@app.route("/video_feed")
def video_feed():
    # Devuelve la respuesta generada por la funci√≥n generate_frames
    return Response(generate_frames(),
                    mimetype="multipart/x-mixed-replace; boundary=frame")

# ######################################################
# ## CARGA DE CONFIGURACI√ìN DESDE JSON ##
# ######################################################
try:
    with open(CONFIG_FILE, 'r') as f:
        config = json.load(f)
    PX_PER_CM = config['pixels_por_cm']
    ORIGEN_X, ORIGEN_Y = config['origen_grilla_px']
    print(f"‚úÖ Configuraci√≥n '{CONFIG_FILE}' cargada exitosamente.")
    print(f"   - Origen del Grid (px): ({ORIGEN_X}, {ORIGEN_Y})")
    print(f"   - Escala (px/cm): {PX_PER_CM:.2f}")
except FileNotFoundError:
    print(f"‚ö†Ô∏è ERROR: No se encontr√≥ el archivo de configuraci√≥n '{CONFIG_FILE}'. Abortando.")
    sys.exit(1)
except KeyError as e:
    print(f"‚ö†Ô∏è ERROR: La clave {e} no se encontr√≥ en el archivo de configuraci√≥n. Abortando.")
    sys.exit(1)

TARGET_FPS = 25

# ######################################################
# ## INICIALIZACI√ìN DE LA COMUNICACI√ìN SERIAL ##
# ######################################################
arduino = None
try:
    arduino = serial.Serial(port=SERIAL_PORT, baudrate=BAUD_RATE, timeout=SERIAL_TIMEOUT)
    print(f"‚úÖ Conectado al Arduino en el puerto {SERIAL_PORT}")
    time.sleep(2) # Espera a que la conexi√≥n se establezca
except serial.SerialException as e:
    print(f"‚ö†Ô∏è ERROR: No se pudo conectar al Arduino en {SERIAL_PORT}. El script correr√° en modo de solo detecci√≥n.")
    print(f"   Detalle del error: {e}")

# Check if model file exists and is valid
# (El resto de la validaci√≥n inicial se mantiene igual)
if (not os.path.exists(model_path)):
    print('ERROR: Model path is invalid or model was not found. Make sure the model filename was entered correctly.')
    sys.exit(0)

model = YOLO(model_path, task='detect')
labels = model.names

img_ext_list = ['.jpg','.JPG','.jpeg','.JPEG','.png','.PNG','.bmp','.BMP']
vid_ext_list = ['.avi','.mov','.mp4','.mkv','.wmv']

if os.path.isdir(img_source):
    source_type = 'folder'
elif os.path.isfile(img_source):
    _, ext = os.path.splitext(img_source)
    if ext in img_ext_list:
        source_type = 'image'
    elif ext in vid_ext_list:
        source_type = 'video'
    else:
        print(f'File extension {ext} is not supported.')
        sys.exit(0)
elif 'usb' in img_source:
    source_type = 'usb'
    usb_idx = int(img_source[3:])
elif 'picamera' in img_source:
    source_type = 'picamera'
    picam_idx = int(img_source[8:])
else:
    print(f'Input {img_source} is invalid. Please try again.')
    sys.exit(0)

resize = False
if user_res:
    resize = True
    resW, resH = int(user_res.split('x')[0]), int(user_res.split('x')[1])

if record:
    if source_type not in ['video','usb']:
        print('Recording only works for video and camera sources. Please try again.')
        sys.exit(0)
    if not user_res:
        print('Please specify resolution to record video at.')
        sys.exit(0)
    
    record_name = 'demo1.avi'
    record_fps = 30
    recorder = cv2.VideoWriter(record_name, cv2.VideoWriter_fourcc(*'MJPG'), record_fps, (resW,resH))

# Load or initialize image source
if source_type == 'image':
    imgs_list = [img_source]
elif source_type == 'folder':
    imgs_list = []
    filelist = glob.glob(img_source + '/*')
    for file in filelist:
        _, file_ext = os.path.splitext(file)
        if file_ext in img_ext_list:
            imgs_list.append(file)
elif source_type == 'video' or source_type == 'usb':
    if source_type == 'video': cap_arg = img_source
    elif source_type == 'usb': cap_arg = usb_idx
    cap = cv2.VideoCapture(cap_arg)

    # Si el usuario no especific√≥ resoluci√≥n, obtenerla de la c√°mara
    if not user_res:
        resW = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        resH = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    else:
        ret = cap.set(3, resW)
        ret = cap.set(4, resH)

elif source_type == 'picamera':
    from picamera2 import Picamera2
    cap = Picamera2()
    cap.configure(cap.create_video_configuration(main={"format": 'RGB888', "size": (resW, resH)}))
    cap.start()

# ######################################################
# ## INICIALIZACI√ìN Y CARGA DEL LOG ##
# ######################################################
posiciones_atacadas_log = cargar_log_ataques(LOG_FILE)
print(f"‚úÖ Log de ataques cargado. {len(posiciones_atacadas_log)} posiciones ya han sido atacadas.")


# ######################################################
# ## NUEVO: BUCLE DE ESPERA DEL COMANDO DE INICIO ##
# ######################################################
if arduino:
    print("\n‚è≥ Esperando comando 'START_DETECTION' del Arduino para iniciar...")
    while True:
        if arduino.in_waiting > 0:
            comando_inicio = arduino.readline().decode('utf-8').strip()
            if comando_inicio == "START_DETECTION":
                print("Comando recibido. ¬°Iniciando detecci√≥n!")
                break # Sale del bucle de espera y contin√∫a con el script
        
        time.sleep(0.1) # Peque√±a pausa para no saturar el CPU
#
# ######################################################
# ## PRE-C√ÅLCULO DEL GRID Y VARIABLES DE CONTROL ##
# ######################################################
# --- C√°lculos basados en la configuraci√≥n JSON y medidas en cm ---
GRID_WIDTH_PX = GRID_COLS_CM * PX_PER_CM
GRID_HEIGHT_PX = GRID_ROWS_CM * PX_PER_CM

# Asumimos que cada celda del grid mide 1x1 cm
CELL_WIDTH_PX = 1 * PX_PER_CM
CELL_HEIGHT_PX = 1 * PX_PER_CM

bbox_colors = [(164,120,87), (68,148,228), (93,97,209), (178,182,133), (88,159,106), 
               (96,202,231), (159,124,168), (169,162,241), (98,118,150), (172,176,184)]

avg_frame_rate = 0
frame_rate_buffer = []
fps_avg_len = 200
img_count = 0

    # Begin inference loop
while True:

    # ######################################################
    # ## NUEVO: OYENTE DE COMANDOS DEL ARDUINO ##
    # ######################################################
    #if arduino and arduino.in_waiting > 0:
    #   # Lee el comando enviado desde Arduino sin bloquear el script
    #  comando_arduino = arduino.readline().decode('utf-8').strip()
    #  
    #  #if comando_arduino == "NAVIGATING":
    #  #   print("\nINFO: Recibido comando para entrar en modo navegaci√≥n.")
    #  #   resetear_log()
#
    t_start = time.perf_counter()

    # (El c√≥digo para cargar el frame se mantiene igual)
    if source_type == 'image' or source_type == 'folder':
        if img_count >= len(imgs_list):
            print('All images have been processed. Exiting program.')
            sys.exit(0)
        img_filename = imgs_list[img_count]
        frame = cv2.imread(img_filename)
        img_count = img_count + 1
    elif source_type == 'video':
        ret, frame = cap.read()
        if not ret:
            print('Reached end of the video file. Exiting program.')
            break
    elif source_type == 'usb':
        ret, frame = cap.read()
        if (frame is None) or (not ret):
            print('Unable to read frames from the camera. This indicates the camera is disconnected or not working. Exiting program.')
            break
    elif source_type == 'picamera':
        frame = cap.capture_array()
        if (frame is None):
            print('Unable to read frames from the Picamera. This indicates the camera is disconnected or not working. Exiting program.')
            break

    # --- INICIO DE LA MODIFICACI√ìN 2: Recortar la imagen ---
    # Se recorta la imagen a 1280x360 desde el centro para evitar distorsi√≥n.
    # Esto ignora el argumento --resolution en favor de un recorte fijo.
    frame = crop_center(frame, 1280, 400)
    # --- FIN DE LA MODIFICACI√ìN 2 ---

    # En tu bucle principal
    #t_inferencia_inicio = time.perf_counter()
    # Run inference on frame
    results = model(frame, verbose=False)
    #t_inferencia_fin = time.perf_counter()
    #print(f"Tiempo de inferencia: {t_inferencia_fin - t_inferencia_inicio:.4f} segundos")

    detections = results[0].boxes
    object_count = 0

    # ######################################################
    # ## DIBUJAR EL GRID EN LA IMAGEN ##
    # ######################################################
    # Dibuja el borde exterior del grid
    pt1 = (ORIGEN_X, ORIGEN_Y)
    pt2 = (int(ORIGEN_X + GRID_WIDTH_PX), int(ORIGEN_Y + GRID_HEIGHT_PX))
    cv2.rectangle(frame, pt1, pt2, (0, 255, 0), 2)

    #Dibuja las l√≠neas internas (opcional, puede ser pesado visualmente)
    for row in range(1, GRID_ROWS_CM):
        y = int(ORIGEN_Y + row * CELL_HEIGHT_PX)
        cv2.line(frame, (ORIGEN_X, y), (int(ORIGEN_X + GRID_WIDTH_PX), y), (0, 255, 0), 1)
    for col in range(1, GRID_COLS_CM):
        x = int(ORIGEN_X + col * CELL_WIDTH_PX)
        cv2.line(frame, (x, ORIGEN_Y), (x, int(ORIGEN_Y + GRID_HEIGHT_PX)), (0, 255, 0), 1)

    # Go through each detection
    for i in range(len(detections)):
        xyxy_tensor = detections[i].xyxy.cpu()
        xyxy = xyxy_tensor.numpy().squeeze()
        xmin, ymin, xmax, ymax = xyxy.astype(int)

        centerX = int((xmin + xmax) / 2)
        centerY = int((ymin + ymax) / 2)

        cv2.circle(frame, (centerX, centerY), 5, (0, 0, 255), -1)

        classidx = int(detections[i].cls.item())
        classname = labels[classidx]
        conf = detections[i].conf.item()

        if conf > min_thresh:
            object_count += 1
            color = bbox_colors[classidx % 10]
            cv2.rectangle(frame, (xmin, ymin), (xmax, ymax), color, 2)
            label = f'{classname}: {int(conf*100)}%'
            labelSize, baseLine = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)
            label_ymin = max(ymin, labelSize[1] + 10)
            cv2.rectangle(frame, (xmin, label_ymin - labelSize[1] - 10), (xmin + labelSize[0], label_ymin + baseLine - 10), color, cv2.FILLED)
            cv2.putText(frame, label, (xmin, label_ymin - 7), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1)

            # ######################################################
            # ## L√ìGICA DE DETECCI√ìN Y ATAQUE ##
            # ######################################################
            if classname == TARGET_CLASS and arduino is not None:
                # --- NUEVO: Verificar si la detecci√≥n est√° DENTRO del grid ---
                is_inside_grid = (ORIGEN_X <= centerX < ORIGEN_X + GRID_WIDTH_PX) and \
                                 (ORIGEN_Y <= centerY < ORIGEN_Y + GRID_HEIGHT_PX)

                if is_inside_grid:
                    # Calcular coordenadas relativas al origen del grid
                    relative_x = centerX - ORIGEN_X
                    relative_y = centerY - ORIGEN_Y

                    # Calcular en qu√© celda est√° el objeto
                    grid_col = int(relative_x // CELL_WIDTH_PX)
                    grid_row = int(relative_y // CELL_HEIGHT_PX)
                    grid_position = grid_row * GRID_COLS_CM + grid_col
                        
                    if grid_position not in posiciones_atacadas_log:
                        
                        # (Env√≠o del comando "ATTACK" al Arduino)
                        command = f"ATTACK,{grid_position}\n"
                        arduino.write(command.encode('utf-8')) 
                        print(f"¬°{TARGET_CLASS} en celda {grid_position}! Enviando comando...")
                        cv2.putText(frame, f"ATTACK: {grid_position}", (centerX, centerY - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)

                        # ######################################################
                        # ## NUEVO: BUCLE DE ESPERA DE CONFIRMACI√ìN ##
                        # ######################################################
                        print("‚è≥ Esperando confirmaci√≥n del Arduino...")
                        # Pausar el video temporalmente mostrando un mensaje
                        overlay = frame.copy()
                        # Obtener dimensiones del frame para centrar el texto
                        frame_h, frame_w, _ = frame.shape
                        cv2.putText(overlay, "ATACANDO...", (frame_w // 2 - 100, frame_h // 2), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 3)
                        cv2.imshow('YOLO detection results', overlay)
                        cv2.waitKey(1) # Esencial para que el overlay se muestre
                        
                        while True:
                            response = arduino.readline().decode('utf-8').strip()
                            if response == "DONE":
                                print("Confirmaci√≥n recibida. Guardando en el log permanente.")
                                posiciones_atacadas_log[grid_position] = time.strftime("%Y-%m-%d %H:%M:%S")
                                guardar_log_ataques(LOG_FILE, posiciones_atacadas_log)
                                break                           

    if source_type in ['video', 'usb', 'picamera']:
        cv2.putText(frame, f'FPS: {avg_frame_rate:0.2f}', (10, 20), cv2.FONT_HERSHEY_SIMPLEX, .7, (0, 255, 255), 2)
    
    cv2.putText(frame, f'Number of objects: {object_count}', (10, 40), cv2.FONT_HERSHEY_SIMPLEX, .7, (0, 255, 255), 2)
    cv2.imshow('YOLO detection results', frame)
    if record: recorder.write(frame)

    # --- INICIO DEL BLOQUE PARA LIMITAR FPS ---
    target_frame_duration = 1 / TARGET_FPS
    elapsed_time = time.perf_counter() - t_start
    
    # Calcula el tiempo que falta para completar el segundo y haz una pausa
    sleep_time = target_frame_duration - elapsed_time
    if sleep_time > 0:
        time.sleep(sleep_time)

    # El c√°lculo de FPS ahora deber√≠a ser cercano a 1
    t_stop = time.perf_counter()
    frame_rate_calc = 1 / (t_stop - t_start)
    # --- FIN DEL BLOQUE PARA LIMITAR FPS ---

    # Cambiamos waitKey a 1ms para que la ventana no se congele
    key = cv2.waitKey(1) 

    if key == ord('q') or key == ord('Q'): # Press 'q' to quit
        break
    elif key == ord('s') or key == ord('S'): # Press 's' to pause inference
        cv2.waitKey()
    elif key == ord('p') or key == ord('P'): # Press 'p' to save a picture of results on this frame
        cv2.imwrite('capture.png',frame)
    
    # Append FPS result to frame_rate_buffer (for finding average FPS over multiple frames)
    if len(frame_rate_buffer) >= fps_avg_len:
        temp = frame_rate_buffer.pop(0)
        frame_rate_buffer.append(frame_rate_calc)
    else:
        frame_rate_buffer.append(frame_rate_calc)

    # Calculate average FPS for past frames
    avg_frame_rate = np.mean(frame_rate_buffer)

# ######################################################
# ## LIMPIEZA DE RECURSOS ##
# ######################################################
print(f'Average pipeline FPS: {avg_frame_rate:.2f}')
if arduino is not None:
    arduino.close() # <-- CERRAR CONEXI√ìN SERIAL
    print("üîå Conexi√≥n serial con Arduino cerrada.")

if source_type in ['video', 'usb']:
    cap.release()
elif source_type == 'picamera':
    cap.stop()
if record: recorder.release()
cv2.destroyAllWindows()